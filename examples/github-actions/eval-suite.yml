# Eval Suite Workflow
# Regression testing for CKB search quality
# Ensures code intelligence accuracy doesn't degrade over time
#
# Usage: Copy to .github/workflows/eval-suite.yml
#
# Prerequisites:
#   Create fixtures in .ckb/fixtures/ with expected query results
#   See: https://github.com/SimplyLiz/CodeMCPWiki/wiki/Hybrid-Retrieval

name: Eval Suite

on:
  pull_request:
    paths:
      - '**/*.go'
      - '**/*.ts'
      - '**/*.py'
      - '.ckb/fixtures/**'
  schedule:
    # Run weekly to catch regressions
    - cron: '0 4 * * 0'
  workflow_dispatch:
    inputs:
      pass_threshold:
        description: 'Minimum pass rate percentage'
        required: false
        default: '90'

permissions:
  contents: read
  pull-requests: write
  checks: write

env:
  PASS_THRESHOLD: 90

jobs:
  eval:
    name: Run Eval Suite
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install CKB
        run: npm install -g @tastehub/ckb

      - name: Check for Fixtures
        id: fixtures
        run: |
          if [ -d ".ckb/fixtures" ] && [ "$(ls -A .ckb/fixtures 2>/dev/null)" ]; then
            echo "found=true" >> $GITHUB_OUTPUT
            echo "count=$(find .ckb/fixtures -name '*.json' | wc -l | tr -d ' ')" >> $GITHUB_OUTPUT
          else
            echo "found=false" >> $GITHUB_OUTPUT
            echo "count=0" >> $GITHUB_OUTPUT
          fi

      - name: Initialize and Index
        if: steps.fixtures.outputs.found == 'true'
        run: |
          ckb init
          ckb index

      - name: Run Eval Suite
        if: steps.fixtures.outputs.found == 'true'
        id: eval
        run: |
          THRESHOLD="${{ github.event.inputs.pass_threshold || env.PASS_THRESHOLD }}"

          ckb eval --fixtures=.ckb/fixtures --format=json > eval-results.json

          PASSED=$(jq '.passedTests // 0' eval-results.json)
          TOTAL=$(jq '.totalTests // 0' eval-results.json)
          FAILED=$(jq '.failedTests | length // 0' eval-results.json)

          if [ "$TOTAL" -gt 0 ]; then
            RATE=$(echo "scale=2; $PASSED * 100 / $TOTAL" | bc)
          else
            RATE=0
          fi

          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "rate=$RATE" >> $GITHUB_OUTPUT

          if (( $(echo "$RATE < $THRESHOLD" | bc -l) )); then
            echo "below_threshold=true" >> $GITHUB_OUTPUT
          else
            echo "below_threshold=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate Report
        if: steps.fixtures.outputs.found == 'true'
        run: |
          cat > eval-report.md << 'HEADER'
          ## Eval Suite Results

          HEADER

          PASSED=${{ steps.eval.outputs.passed }}
          TOTAL=${{ steps.eval.outputs.total }}
          RATE=${{ steps.eval.outputs.rate }}
          THRESHOLD="${{ github.event.inputs.pass_threshold || env.PASS_THRESHOLD }}"

          if (( $(echo "$RATE >= $THRESHOLD" | bc -l) )); then
            echo "### ✅ Pass Rate: ${RATE}% ($PASSED/$TOTAL)" >> eval-report.md
          else
            echo "### ❌ Pass Rate: ${RATE}% ($PASSED/$TOTAL) - Below ${THRESHOLD}% threshold" >> eval-report.md
          fi

          echo "" >> eval-report.md

          # Failed tests
          FAILED=${{ steps.eval.outputs.failed }}
          if [ "$FAILED" -gt 0 ]; then
            echo "### Failed Tests" >> eval-report.md
            echo "" >> eval-report.md
            echo "| Test | Expected | Actual | Reason |" >> eval-report.md
            echo "|------|----------|--------|--------|" >> eval-report.md

            jq -r '.failedTests[:20][] | "| `\(.id // .name)` | \(.expected // "—") | \(.actual // "—") | \(.reason // "—") |"' eval-results.json >> eval-report.md

            if [ "$FAILED" -gt 20 ]; then
              echo "" >> eval-report.md
              echo "*...and $((FAILED - 20)) more failed tests*" >> eval-report.md
            fi
          fi

          echo "" >> eval-report.md
          echo "<details>" >> eval-report.md
          echo "<summary>Test Categories</summary>" >> eval-report.md
          echo "" >> eval-report.md

          # Category breakdown
          jq -r '
            .results | group_by(.category // "uncategorized") |
            map({category: .[0].category // "uncategorized", passed: [.[] | select(.passed)] | length, total: length}) |
            .[] | "- **\(.category)**: \(.passed)/\(.total)"
          ' eval-results.json >> eval-report.md 2>/dev/null || echo "- No category data available" >> eval-report.md

          echo "" >> eval-report.md
          echo "</details>" >> eval-report.md
          echo "" >> eval-report.md
          echo "---" >> eval-report.md
          echo "*Generated by CKB eval suite*" >> eval-report.md

      - name: Post PR Comment
        if: github.event_name == 'pull_request' && steps.fixtures.outputs.found == 'true'
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          header: eval-suite
          path: eval-report.md

      - name: Create Check Run
        if: steps.fixtures.outputs.found == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const passed = parseInt('${{ steps.eval.outputs.passed }}');
            const total = parseInt('${{ steps.eval.outputs.total }}');
            const rate = parseFloat('${{ steps.eval.outputs.rate }}');
            const threshold = parseFloat('${{ github.event.inputs.pass_threshold || env.PASS_THRESHOLD }}');
            const belowThreshold = '${{ steps.eval.outputs.below_threshold }}' === 'true';

            await github.rest.checks.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              name: 'Eval Suite',
              head_sha: context.sha,
              status: 'completed',
              conclusion: belowThreshold ? 'failure' : 'success',
              output: {
                title: belowThreshold ? `Failed: ${rate}% < ${threshold}%` : `Passed: ${rate}%`,
                summary: `${passed}/${total} tests passed (${rate}%)`
              }
            });

      - name: Upload Results
        if: steps.fixtures.outputs.found == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: eval-results
          path: |
            eval-results.json
            eval-report.md
          retention-days: 30

      - name: No Fixtures Warning
        if: steps.fixtures.outputs.found == 'false'
        run: |
          echo "::warning::No eval fixtures found in .ckb/fixtures/"
          echo ""
          echo "To create fixtures:"
          echo "  1. mkdir -p .ckb/fixtures"
          echo "  2. Add JSON files with expected query results"
          echo "  3. See documentation for fixture format"

      - name: Fail on Threshold
        if: steps.eval.outputs.below_threshold == 'true'
        run: |
          echo "::error::Eval suite pass rate ${{ steps.eval.outputs.rate }}% is below threshold ${{ github.event.inputs.pass_threshold || env.PASS_THRESHOLD }}%"
          exit 1

      - name: Summary
        if: always() && steps.fixtures.outputs.found == 'true'
        run: |
          echo "## Eval Suite Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Passed | ${{ steps.eval.outputs.passed }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Total | ${{ steps.eval.outputs.total }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Pass Rate | ${{ steps.eval.outputs.rate }}% |" >> $GITHUB_STEP_SUMMARY
          echo "| Failed | ${{ steps.eval.outputs.failed }} |" >> $GITHUB_STEP_SUMMARY
