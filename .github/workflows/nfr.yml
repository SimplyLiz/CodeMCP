name: NFR Tests

on:
  pull_request:
    branches: [develop, main]

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  pull-requests: write

jobs:
  nfr:
    name: NFR Scenarios
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'
          cache: true

      - name: Download dependencies
        run: go mod download

      - name: Run NFR Tests
        id: nfr
        run: |
          # Run NFR tests
          set +e
          go test -v -run TestNFRScenarios ./internal/mcp/... 2>&1 | tee nfr-output.txt
          TEST_EXIT=${PIPESTATUS[0]}
          set -e

          # Parse results - count all PASS/FAIL lines including subtests
          PASS=$(grep -c -- "--- PASS" nfr-output.txt) || PASS=0
          FAIL=$(grep -c -- "--- FAIL" nfr-output.txt) || FAIL=0
          TOTAL=$((PASS + FAIL))

          # Job summary
          echo "## ðŸ“Š NFR Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| âœ… Passed | $PASS |" >> $GITHUB_STEP_SUMMARY
          echo "| âŒ Failed | $FAIL |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ“Š Total | $TOTAL |" >> $GITHUB_STEP_SUMMARY

          # Set outputs for PR comment
          echo "pass=$PASS" >> $GITHUB_OUTPUT
          echo "fail=$FAIL" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "exit_code=$TEST_EXIT" >> $GITHUB_OUTPUT

          exit $TEST_EXIT

      - name: Parse NFR metrics
        id: metrics
        if: always()
        run: |
          # Extract actual token counts and timings from test output
          # Format: tool_tier_actual_baseline_status

          cat > parse_nfr.py << 'EOF'
          import re

          rows = []

          with open("nfr-output.txt", "r") as f:
              content = f.read()

          # Parse: "searchSymbols_small: 3500 bytes (baseline: 3600, max: 3960) [1.234ms]"
          pattern = r'(\w+)_(\w+): (\d+) bytes \(baseline: (\d+), max: (\d+)\) \[([^\]]+)\]'
          for match in re.finditer(pattern, content):
              tool, tier, actual, baseline, max_allowed, timing = match.groups()
              actual, baseline, max_allowed = int(actual), int(baseline), int(max_allowed)
              diff_pct = ((actual - baseline) / baseline) * 100
              budget_pct = (actual / max_allowed) * 100 if max_allowed > 0 else 0

              if diff_pct >= 10:
                  verdict = "FAIL"
              elif diff_pct >= 5:
                  verdict = "WARN"
              elif diff_pct <= -5:
                  verdict = "GOOD"
              else:
                  verdict = "OK"

              rows.append({
                  "tool": tool, "tier": tier, "actual": actual,
                  "baseline": baseline, "max": max_allowed,
                  "diff_pct": diff_pct, "budget_pct": budget_pct,
                  "timing": timing, "verdict": verdict
              })

          if rows:
              # Categorize
              fails = [r for r in rows if r["verdict"] == "FAIL"]
              warns = [r for r in rows if r["verdict"] == "WARN"]
              goods = [r for r in rows if r["verdict"] == "GOOD"]
              regressions = fails + warns
              improvements = goods

              # Find highlights
              worst = max(rows, key=lambda r: r["diff_pct"])
              best = min(rows, key=lambda r: r["diff_pct"])
              riskiest = max(rows, key=lambda r: r["budget_pct"])

              total = len(rows)
              passed = total - len(fails)

              # Headline
              if fails:
                  print(f"## NFR Budget âŒ {len(fails)} failed\n")
              else:
                  print(f"## NFR Budget âœ… {passed} passed\n")

              # Three key metrics
              print(f"**Worst regression:** `{worst['tool']}/{worst['tier']}` **{worst['diff_pct']:+.1f}%** ({worst['actual']:,}B) â€¢ Budget {worst['budget_pct']:.0f}%  ")
              print(f"**Best improvement:** `{best['tool']}/{best['tier']}` **{best['diff_pct']:+.1f}%** ({best['actual']:,}B) â€¢ Budget {best['budget_pct']:.0f}%  ")
              if riskiest["budget_pct"] >= 90:
                  print(f"**Closest to limit:** `{riskiest['tool']}/{riskiest['tier']}` Budget **{riskiest['budget_pct']:.0f}%** (risk)\n")
              else:
                  print(f"**Closest to limit:** `{riskiest['tool']}/{riskiest['tier']}` Budget {riskiest['budget_pct']:.0f}%\n")

              # Summary counts
              reg_str = f"{len(fails)} FAIL / {len(warns)} WARN" if regressions else "0"
              print("| Regressions (FAIL â‰¥+10%, WARN â‰¥+5%) | Improvements (â‰¤-5%) | Scenarios |")
              print("|---:|---:|---:|")
              print(f"| {reg_str} | {len(improvements)} | {total} |\n")

              # Diff block for quick visual scan
              if regressions or improvements:
                  print("```diff")
                  for r in sorted(regressions, key=lambda x: -x["diff_pct"])[:3]:
                      print(f"- {r['verdict']:4} {r['tool']}/{r['tier']:<20} {r['diff_pct']:+6.1f}%  {r['actual']:>8,}B  budget {r['budget_pct']:>2.0f}%  {r['timing']}")
                  for r in sorted(improvements, key=lambda x: x["diff_pct"])[:3]:
                      print(f"+ GOOD {r['tool']}/{r['tier']:<20} {r['diff_pct']:+6.1f}%  {r['actual']:>8,}B  budget {r['budget_pct']:>2.0f}%  {r['timing']}")
                  print("```\n")

              # Regressions table
              if regressions:
                  print("### Regressions\n")
                  print("| Scenario | Actual (B) | Î” vs base | Budget | Time | Verdict |")
                  print("|---|---:|---:|---:|---:|---|")
                  for r in sorted(regressions, key=lambda x: -x["diff_pct"]):
                      v = f"**{r['verdict']}**" if r["verdict"] == "FAIL" else r["verdict"]
                      print(f"| {r['tool']} / {r['tier']} | {r['actual']:,} | {r['diff_pct']:+.1f}% | {r['budget_pct']:.0f}% | {r['timing']} | {v} |")
                  print()

              # Improvements table
              if improvements:
                  print("### Improvements\n")
                  print("| Scenario | Actual (B) | Î” vs base | Budget | Time | Verdict |")
                  print("|---|---:|---:|---:|---:|---|")
                  for r in sorted(improvements, key=lambda x: x["diff_pct"]):
                      print(f"| {r['tool']} / {r['tier']} | {r['actual']:,} | {r['diff_pct']:+.1f}% | {r['budget_pct']:.0f}% | {r['timing']} | GOOD |")
                  print()

              # Full breakdown in details
              print("<details><summary>All scenarios</summary>\n")
              print("| Scenario | Actual (B) | Baseline (B) | Max (B) | Î” | Budget | Time |")
              print("|---|---:|---:|---:|---:|---:|---:|")
              for r in sorted(rows, key=lambda x: -x["diff_pct"]):
                  print(f"| {r['tool']} / {r['tier']} | {r['actual']:,} | {r['baseline']:,} | {r['max']:,} | {r['diff_pct']:+.1f}% | {r['budget_pct']:.0f}% | {r['timing']} |")
              print("\n</details>")
          else:
              print("No token metrics found in output")
          EOF

          if ! python3 parse_nfr.py > nfr-table.md 2>&1; then
            echo "::warning::Failed to parse NFR metrics"
            echo "No metrics parsed" > nfr-table.md
          fi
          cat nfr-table.md

      - name: Comment on PR
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let body = 'No NFR metrics available';
            try {
              body = fs.readFileSync('nfr-table.md', 'utf8');
            } catch (e) {}

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' && c.body.includes('NFR Budget')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

      - name: Upload NFR results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nfr-results
          path: |
            nfr-output.txt
            nfr-table.md
          retention-days: 7
